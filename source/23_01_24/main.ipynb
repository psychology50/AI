{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures # 변환기 (데이터 바꾸는 용도) 수의 조합 생성\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression # 선형 회귀\n",
    "from sklearn.linear_model import Ridge # 릿지 회귀\n",
    "from sklearn.linear_model import Lasso # 라쏘 회귀\n",
    "\n",
    "df = pd.read_csv('https://bit.ly/perch_csv')\n",
    "perch_full = df.to_numpy()\n",
    "\n",
    "perch_weight = np.array(\n",
    "    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, \n",
    "     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, \n",
    "     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, \n",
    "     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, \n",
    "     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, \n",
    "     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, \n",
    "     1000.0, 1000.0]\n",
    "     )\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)\n",
    "\n",
    "poly = PolynomialFeatures()\n",
    "poly.fit([[2, 3]])\n",
    "print(poly.transform([[2, 3]])) # fit & transform 항상 같이 나온다\n",
    "\n",
    "poly = PolynomialFeatures(include_bias=False) # bias 1 값을 제외할 수도 있다.\n",
    "poly.fit([[2, 3]])\n",
    "print(poly.transform([[2, 3]]))\n",
    "\n",
    "# 변환 시작\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "print(train_poly.shape) # (42, 9) : 42개 데이터의 9개 특성치\n",
    "poly.get_feature_names()\n",
    "\n",
    "test_poly = poly.transform(test_input) # test set은 학습 없이 변환한다.\n",
    "\n",
    "# 다중 회귀 모델 훈련 시작\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_poly, train_target)\n",
    "print(lr.score(train_poly, train_target)) # 0.9903183436982124\n",
    "print(lr.score(test_poly, test_target))   # 0.9714559911594134\n",
    "# 다항 회귀까지 했을 때보다 좋은 학습 결과가 나왔다\n",
    "\n",
    "# 그렇다면, 특성치가 많으면 무조건 좋을까?\n",
    "poly = PolynomialFeatures(degree=5, include_bias=False) # 5차항으로 생성\n",
    "\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "test_poly = poly.transform(test_input)\n",
    "print(train_poly.shape) # (42, 55) : 42개 데이터의 55개 특성치...잘못된 데이터\n",
    "\n",
    "lr.fit(train_poly, train_target)\n",
    "print(lr.score(train_poly, train_target)) # 0.9999999999991097\n",
    "print(lr.score(test_poly, test_target))   # -144.40579242684848\n",
    "# 과적합으로 인해 실패한 케이스\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀에 규제를 하기 위해서는 정규화를 해야한다. 복잡도에 적절한 규제 강도를 탐색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import PolynomialFeatures # 변환기 (데이터 바꾸는 용도) 수의 조합 생성\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LinearRegression # 선형 회귀\n",
    "# from sklearn.linear_model import Ridge # 릿지 회귀\n",
    "# from sklearn.linear_model import Lasso # 라쏘 회귀\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 표준화\n",
    "ss = StandardScaler() # 특성을 표준 점수로 자동 변환하는 변환기의 일종(평균과 표준편차를 이용한 표준 점수 산출)\n",
    "ss.fit(train_poly) # 훈련 세트에 적용한 객체를 테스트 세트에 적용\n",
    "\n",
    "train_scaled = ss.transform(train_poly)\n",
    "test_scaled = ss.transform(test_poly) # 표준 점수로 훈련/테스트 세트 변환\n",
    "\n",
    "print(train_scaled)\n",
    "\n",
    "# 규제1. 릿지 회귀\n",
    "# 가중치의 제곱을 벌칙으로 사용, L2 규제\n",
    "# 규제 강도 조절을 위해 하이퍼 파라미터를 조정한다.\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_scaled, train_target) # target은 스케일되지 않은 그대로 사용\n",
    "print(ridge.score(train_scaled, train_target)) # 0.9896101671037343\n",
    "print(ridge.score(test_scaled, test_target))   # 0.9790693977615391\n",
    "# 규제를 통한 과대 적합 해소\n",
    "\n",
    "# 적절한 규제 강도 찾기 : alpha 값의 변화에 따른 결정계수(R^2) 탐색\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "  ridge = Ridge(alpha = alpha)\n",
    "  ridge.fit(train_scaled, train_target) # 릿지 모델 훈련\n",
    "  train_score.append(ridge.score(train_scaled, train_target))\n",
    "  test_score.append(ridge.score(test_scaled, test_target))\n",
    "\n",
    "plt.plot(np.log10(alpha_list), train_score)\n",
    "plt.plot(np.log10(alpha_list), test_score)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제2. 라쏘 회귀\n",
    "# 가중치의 절대값을 벌칙으로 사용, L1 규제\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(train_scaled, train_target)\n",
    "\n",
    "print(lasso.score(train_scaled, train_target)) # 0.989789897208096\n",
    "print(lasso.score(test_scaled, test_target))  # 0.9800593698421883\n",
    "\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "  lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "  lasso.fit(train_scaled, train_target)\n",
    "  train_score.append(lasso.score(train_scaled, train_target))\n",
    "  test_score.append(lasso.score(test_scaled, test_target))\n",
    "\n",
    "plt.plot(np.log10(alpha_list), train_score)\n",
    "plt.plot(np.log10(alpha_list), test_score)\n",
    "plt.show()\n",
    "\n",
    "# 라쏘 회귀는 특성의 가중치를 0으로 만들 수도 있다. (특성 무시) \n",
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(train_scaled, train_target)\n",
    "\n",
    "print(lasso.score(train_scaled, train_target)) # 0.9888067471131867\n",
    "print(lasso.score(test_scaled, test_target))   # 0.9824470598706695\n",
    "\n",
    "print(np.sum(lasso.coef_ == 0)) # 특성 가중치가 0인 것이 40개 존재 => 유용한 특성을 골라내는 용도로 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류하는데 사용하는 알고리즘. (이름에서 혼동하지 말 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = pd.read_csv('https://bit.ly/fish_csv')\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "# K-최근접 이웃 분류의 확률 예측\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors = 3)\n",
    "kn.fit(train_scaled, train_target)\n",
    "\n",
    "print(kn.score(train_scaled, train_target)) # 0.8907563025210085\n",
    "print(kn.score(test_scaled, test_target))   # 0.85\n",
    "\n",
    "print(kn.predict(test_scaled[:5])) # 예측 시작\n",
    "proba = kn.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=4)) # predict_proba() : 각 클래스별 확률값 반환\n",
    "\n",
    "distances, indexes = kn.kneighbors(test_scaled[3:4])\n",
    "print(train_target[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀\n",
    "\n",
    "# sigmoid 함수 식\n",
    "z = np.arange(-5, 5, 0.1)\n",
    "phi = 1 / (1 + np.exp(-z))\n",
    "\n",
    "plt.plot(z, phi)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 (이진 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit\n",
    "\n",
    "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt') # boolean index retrun\n",
    "train_bream_smelt = train_scaled[bream_smelt_indexes]\n",
    "target_bream_smelt = train_target[bream_smelt_indexes]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_bream_smelt, target_bream_smelt)\n",
    "\n",
    "print(lr.predict(train_bream_smelt[:5]))\n",
    "print(lr.predict_proba(train_bream_smelt[:5]))\n",
    "\n",
    "# 로지스틱 회귀 식(계수, 절편) 확인\n",
    "print(lr.coef_, lr.intercept_) # 특성 5개에 대한 가중치(계수) 5개 + 절편 1개\n",
    "\n",
    "decisions = lr.decision_function(train_bream_smelt[:5]) # 입력에 대한 표준 점수 z 출력 함수(평균에서 몇 표준편차만큼?)\n",
    "print(expit(decisions)) # 표준점수 z를 sigmoid함수 expit에 입력하여 확률 산출 (양성일 확률)\n",
    "# [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 (다중 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=20, max_iter=1000) # C(alpha 대신 사용)가 클수록 규제 약함, 반복횟수 100(기본) -> 1000\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "print(lr.score(train_scaled, train_target)) # 0.9327731092436975\n",
    "print(lr.score(test_scaled, test_target))   # 0.925\n",
    "\n",
    "proba = lr.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=3))\n",
    "print(lr.coef_.shape, lr.intercept_.shape) # (7,5) (7,) : 7개 항에 5개씩 특성치가 존재하고, 각 항별 식의 절편 개수\n",
    "\n",
    "\n",
    "# 소프트 맥스 함수 : 7개의 클래스(다중 분류)를 각각 0~1 사이 확류로 표시\n",
    "# sigmoid -> 이진 분류\n",
    "# softmax -> 다중 분류\n",
    "\n",
    "decision = lr.decision_function(test_scaled[:5])\n",
    "print(np.round(decision, decimals=2))\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "proba = softmax(decision, axis=1)\n",
    "print(np.round(proba, decimals=3)) # 위의 결과와 같다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv')\n",
    "\n",
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "sc = SGDClassifier(loss='log', max_iter=10, random_state=42) # 확률적 경사하강법\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target)) # 0.773109243697479\n",
    "print(sc.score(test_scaled, test_target))   # 0.775\n",
    "\n",
    "sc.partial_fit(train_scaled, train_target) # 이전 학습 결과를 유지하면서 1 에포크 추가 훈련\n",
    "\n",
    "print(sc.score(train_scaled, train_target)) # 0.8151260504201681\n",
    "print(sc.score(test_scaled, test_target))   # 0.85\n",
    "# 향상되었다 -> 얼마나 partial_fit()을 반복할까? -> 에포크 횟수 조절"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에포크와 과대/과소적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "classes = np.unique(train_target)\n",
    "\n",
    "for _ in range(0, 300):\n",
    "  sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "\n",
    "  train_score.append(sc.score(train_scaled, train_target))\n",
    "  test_score.append(sc.score(test_scaled, test_target))\n",
    "\n",
    "plt.plot(train_score)\n",
    "plt.plot(test_score)\n",
    "plt.show()\n",
    "\n",
    "# 손실 함수 log 사용\n",
    "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target)) # 0.957983193277311\n",
    "print(sc.score(test_scaled, test_target))   # 0.925\n",
    "\n",
    "# 손실 함수 hinge 사용\n",
    "sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target)) # 0.9495798319327731\n",
    "print(sc.score(test_scaled, test_target))   # 0.925"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# 전처리\n",
    "wine = pd.read_csv('https://bit.ly/wine-date')\n",
    "\n",
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "print(lr.score(train_scaled, train_target))\n",
    "print(lr.score(test_scaled, test_target))\n",
    "\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결정 트리\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(train_scaled, train_target)\n",
    "\n",
    "print(dt.score(train_scaled, train_target)) # 0.996921300750433\n",
    "print(dt.score(test_scaled, test_target))   # 0.8592307692307692\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plot_tree(dt)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가지치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt.fit(train_scaled, train_target)\n",
    "\n",
    "print(dt.score(train_scaled, train_target)) # 0.8454877814123533\n",
    "print(dt.score(test_scaled, test_target))   # 0.8415384615384616\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt.fit(train_input, train_target)\n",
    "\n",
    "print(dt.score(train_input, train_target)) # 0.8454877814123533\n",
    "print(dt.score(test_input, test_target))   # 0.8415384615384616\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])\n",
    "plt.show()\n",
    "\n",
    "print(dt.feature_importances_) # [0.12345626 0.86862934 0.0079144 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인 문제\n",
    "\n",
    "dt = DecisionTreeClassifier(min_impurity_decrease=0.0005, random_state=42)\n",
    "dt.fit(train_input, train_target)\n",
    "\n",
    "print(dt.score(train_input, train_target))\n",
    "print(dt.score(test_input, test_target))\n",
    "\n",
    "plt.figure(figsize=(20,15), dpi=300)\n",
    "plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
